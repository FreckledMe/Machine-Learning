{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15c32f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "161917a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(x_batch, y_batch, lr, w, b):\n",
    "    y_pred = np.matmul(x_batch,w) + b\n",
    "    error = y_batch - y_pred\n",
    "    \n",
    "    w_new = w + lr * np.matmul(error,x_batch)\n",
    "    b_new = b + lr * error.sum()\n",
    "    \n",
    "    return w_new,b_new\n",
    "    \n",
    "def MiniBatchGD(x,y,batch_size = 20,epochs = 25, lr = 0.005):\n",
    "    n_values = x.shape[0]\n",
    "    w = np.zeros(x.shape[1])\n",
    "    b = 0\n",
    "    \n",
    "    regression_coef = []\n",
    "    for _ in range(epochs):\n",
    "        batch = np.random.choice(range(n_values),batch_size)\n",
    "        x_batch = x[batch,:]\n",
    "        y_batch = y[batch]\n",
    "        w,b = MSE(x_batch,y_batch,lr,w,b)\n",
    "        \n",
    "        regression_coef.append(np.hstack((w,b)))\n",
    "        \n",
    "    return regression_coef\n",
    "\n",
    "data = np.loadtxt(\"data.csv\",delimiter=',')\n",
    "x = data[:,:-1]\n",
    "y = data[:,-1]\n",
    "regression_coef = MiniBatchGD(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79761fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(regression_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926859ed",
   "metadata": {},
   "source": [
    "# SKlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "465ea9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a722b03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Life expectancy</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>52.8</td>\n",
       "      <td>20.62058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>76.8</td>\n",
       "      <td>26.44657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>75.5</td>\n",
       "      <td>24.59620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>84.6</td>\n",
       "      <td>27.63048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>56.7</td>\n",
       "      <td>22.25083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Vanuatu</td>\n",
       "      <td>63.4</td>\n",
       "      <td>26.78926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>West Bank and Gaza</td>\n",
       "      <td>74.1</td>\n",
       "      <td>26.57750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>74.1</td>\n",
       "      <td>20.91630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>51.1</td>\n",
       "      <td>20.68321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>47.3</td>\n",
       "      <td>22.02660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Country  Life expectancy       BMI\n",
       "0           Afghanistan             52.8  20.62058\n",
       "1               Albania             76.8  26.44657\n",
       "2               Algeria             75.5  24.59620\n",
       "3               Andorra             84.6  27.63048\n",
       "4                Angola             56.7  22.25083\n",
       "..                  ...              ...       ...\n",
       "158             Vanuatu             63.4  26.78926\n",
       "159  West Bank and Gaza             74.1  26.57750\n",
       "160             Vietnam             74.1  20.91630\n",
       "161              Zambia             51.1  20.68321\n",
       "162            Zimbabwe             47.3  22.02660\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bmi.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "173ec22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "x_train,x_test,y_train,y_test = train_test_split(df[['BMI']],df[['Life expectancy']],test_size = 0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f62b7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Linear Regression accuracy : 35.40313361524452%\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train)\n",
    "print(f'Sklearn Linear Regression accuracy : {model.score(x_test,y_test)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c37b125",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e3e660ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d461040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5add8afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Life expectancy</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>52.8</td>\n",
       "      <td>20.62058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>76.8</td>\n",
       "      <td>26.44657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>75.5</td>\n",
       "      <td>24.59620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>84.6</td>\n",
       "      <td>27.63048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>56.7</td>\n",
       "      <td>22.25083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Vanuatu</td>\n",
       "      <td>63.4</td>\n",
       "      <td>26.78926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>West Bank and Gaza</td>\n",
       "      <td>74.1</td>\n",
       "      <td>26.57750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>74.1</td>\n",
       "      <td>20.91630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>51.1</td>\n",
       "      <td>20.68321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>47.3</td>\n",
       "      <td>22.02660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Country  Life expectancy       BMI\n",
       "0           Afghanistan             52.8  20.62058\n",
       "1               Albania             76.8  26.44657\n",
       "2               Algeria             75.5  24.59620\n",
       "3               Andorra             84.6  27.63048\n",
       "4                Angola             56.7  22.25083\n",
       "..                  ...              ...       ...\n",
       "158             Vanuatu             63.4  26.78926\n",
       "159  West Bank and Gaza             74.1  26.57750\n",
       "160             Vietnam             74.1  20.91630\n",
       "161              Zambia             51.1  20.68321\n",
       "162            Zimbabwe             47.3  22.02660\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('bmi.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "752bc385",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "87c3a4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2994e-06 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a808da7cd0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b7ce7f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 8.3266e-06 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8.326624083565548e-06, 0.0]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f060a569",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7abc021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn,optim,cuda,from_numpy,save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "436b7fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network =nn.Linear(1,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3ebe4a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (network): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6d3b3a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.MSELoss(reduction='mean')\n",
    "optimize = optim.Adam(model.parameters(),lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "16c6c408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "76f57daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = torch.Tensor(x_train)\n",
    "y_tensor = torch.Tensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "54fff1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 | Loss: 3627.565185546875\n",
      "Epoch - 1 | Loss: 4136.01123046875\n",
      "Epoch - 1 | Loss: 3284.799560546875\n",
      "Epoch - 1 | Loss: 2505.1796875\n",
      "Epoch - 1 | Loss: 3881.890625\n",
      "Epoch - 1 | Loss: 3419.325927734375\n",
      "Epoch - 1 | Loss: 3020.7978515625\n",
      "Epoch - 1 | Loss: 4451.8251953125\n",
      "Epoch - 1 | Loss: 3254.7490234375\n",
      "Epoch - 1 | Loss: 3739.12158203125\n",
      "Epoch - 1 | Loss: 2439.047119140625\n",
      "Epoch - 1 | Loss: 4338.0703125\n",
      "Epoch - 1 | Loss: 1806.96142578125\n",
      "Epoch - 1 | Loss: 2222.240234375\n",
      "Epoch - 1 | Loss: 2057.9775390625\n",
      "Epoch - 1 | Loss: 3423.107421875\n",
      "Epoch - 1 | Loss: 4349.22802734375\n",
      "Epoch - 1 | Loss: 3069.197265625\n",
      "Epoch - 1 | Loss: 3455.688232421875\n",
      "Epoch - 1 | Loss: 3111.752197265625\n",
      "Epoch - 1 | Loss: 3303.033447265625\n",
      "Epoch - 1 | Loss: 4038.076904296875\n",
      "Epoch - 1 | Loss: 2982.62890625\n",
      "Epoch - 1 | Loss: 3402.95263671875\n",
      "Epoch - 1 | Loss: 2007.07861328125\n",
      "Epoch - 1 | Loss: 3607.285888671875\n",
      "Epoch - 1 | Loss: 2037.0650634765625\n",
      "Epoch - 1 | Loss: 1645.8743896484375\n",
      "Epoch - 1 | Loss: 3832.651611328125\n",
      "Epoch - 1 | Loss: 2566.612548828125\n",
      "Epoch - 1 | Loss: 2946.9130859375\n",
      "Epoch - 1 | Loss: 3652.182373046875\n",
      "Epoch - 1 | Loss: 2343.592041015625\n",
      "Epoch - 1 | Loss: 2726.867919921875\n",
      "Epoch - 1 | Loss: 2903.4716796875\n",
      "Epoch - 1 | Loss: 2133.232177734375\n",
      "Epoch - 1 | Loss: 1292.755615234375\n",
      "Epoch - 1 | Loss: 2076.444091796875\n",
      "Epoch - 1 | Loss: 2247.6552734375\n",
      "Epoch - 1 | Loss: 1695.24609375\n",
      "Epoch - 1 | Loss: 2651.617431640625\n",
      "Epoch - 1 | Loss: 1945.5528564453125\n",
      "Epoch - 1 | Loss: 1266.7744140625\n",
      "Epoch - 1 | Loss: 3153.45166015625\n",
      "Epoch - 1 | Loss: 2652.839111328125\n",
      "Epoch - 1 | Loss: 1255.7236328125\n",
      "Epoch - 1 | Loss: 1566.3328857421875\n",
      "Epoch - 1 | Loss: 2753.345947265625\n",
      "Epoch - 1 | Loss: 587.4256591796875\n",
      "Epoch - 1 | Loss: 2545.671142578125\n",
      "Epoch - 1 | Loss: 2964.6767578125\n",
      "Epoch - 1 | Loss: 3187.705322265625\n",
      "Epoch - 1 | Loss: 1377.2149658203125\n",
      "Epoch - 1 | Loss: 1418.7298583984375\n",
      "Epoch - 1 | Loss: 504.6505126953125\n",
      "Epoch - 1 | Loss: 1590.8450927734375\n",
      "Epoch - 1 | Loss: 1818.6458740234375\n",
      "Epoch - 1 | Loss: 1189.035888671875\n",
      "Epoch - 1 | Loss: 2850.930419921875\n",
      "Epoch - 1 | Loss: 1373.5728759765625\n",
      "Epoch - 1 | Loss: 2547.492919921875\n",
      "Epoch - 1 | Loss: 2207.9384765625\n",
      "Epoch - 1 | Loss: 3104.672607421875\n",
      "Epoch - 1 | Loss: 942.255126953125\n",
      "Epoch - 1 | Loss: 839.4683837890625\n",
      "Epoch - 1 | Loss: 2114.82666015625\n",
      "Epoch - 1 | Loss: 2101.53955078125\n",
      "Epoch - 1 | Loss: 1768.5120849609375\n",
      "Epoch - 1 | Loss: 1991.70458984375\n",
      "Epoch - 1 | Loss: 2512.48583984375\n",
      "Epoch - 1 | Loss: 810.489501953125\n",
      "Epoch - 1 | Loss: 1520.5379638671875\n",
      "Epoch - 1 | Loss: 2459.406494140625\n",
      "Epoch - 1 | Loss: 2483.58837890625\n",
      "Epoch - 1 | Loss: 1782.9254150390625\n",
      "Epoch - 1 | Loss: 1359.447998046875\n",
      "Epoch - 1 | Loss: 1103.331787109375\n",
      "Epoch - 1 | Loss: 1895.77490234375\n",
      "Epoch - 1 | Loss: 2428.915283203125\n",
      "Epoch - 1 | Loss: 1485.9786376953125\n",
      "Epoch - 1 | Loss: 1834.2841796875\n",
      "Epoch - 1 | Loss: 1360.1063232421875\n",
      "Epoch - 1 | Loss: 1971.740234375\n",
      "Epoch - 1 | Loss: 1001.7957763671875\n",
      "Epoch - 1 | Loss: 1848.4151611328125\n",
      "Epoch - 1 | Loss: 1523.5635986328125\n",
      "Epoch - 1 | Loss: 2058.95263671875\n",
      "Epoch - 1 | Loss: 1880.3712158203125\n",
      "Epoch - 1 | Loss: 1349.3450927734375\n",
      "Epoch - 1 | Loss: 1780.8983154296875\n",
      "Epoch - 1 | Loss: 699.870361328125\n",
      "Epoch - 1 | Loss: 2033.2003173828125\n",
      "Epoch - 1 | Loss: 1444.9617919921875\n",
      "Epoch - 1 | Loss: 1674.4384765625\n",
      "Epoch - 1 | Loss: 2331.7900390625\n",
      "Epoch - 1 | Loss: 1496.3760986328125\n",
      "Epoch - 1 | Loss: 1871.4056396484375\n",
      "Epoch - 1 | Loss: 1828.964599609375\n",
      "Epoch - 1 | Loss: 1270.1239013671875\n",
      "Epoch - 1 | Loss: 1717.4945068359375\n",
      "Epoch - 1 | Loss: 1046.7196044921875\n",
      "Epoch - 1 | Loss: 1331.2276611328125\n",
      "Epoch - 1 | Loss: 795.396240234375\n",
      "Epoch - 1 | Loss: 2019.5760498046875\n",
      "Epoch - 1 | Loss: 1966.409423828125\n",
      "Epoch - 1 | Loss: 1120.7532958984375\n",
      "Epoch - 1 | Loss: 737.2968139648438\n",
      "Epoch - 1 | Loss: 423.4733581542969\n",
      "Epoch - 1 | Loss: 1225.4088134765625\n",
      "Epoch - 1 | Loss: 1770.55224609375\n",
      "Epoch - 1 | Loss: 1067.818603515625\n",
      "Epoch - 1 | Loss: 1262.140625\n",
      "Epoch - 1 | Loss: 1374.39697265625\n",
      "Epoch - 1 | Loss: 1169.2701416015625\n",
      "Epoch - 1 | Loss: 1402.369140625\n",
      "Epoch - 1 | Loss: 651.1187744140625\n",
      "Epoch - 1 | Loss: 1405.31884765625\n",
      "Epoch - 1 | Loss: 604.4662475585938\n",
      "Epoch - 1 | Loss: 1269.7938232421875\n",
      "Epoch - 1 | Loss: 1197.1453857421875\n",
      "Epoch - 1 | Loss: 839.5560913085938\n",
      "Epoch - 1 | Loss: 1434.2489013671875\n",
      "Epoch - 1 | Loss: 756.6856079101562\n",
      "Epoch - 1 | Loss: 159.96067810058594\n",
      "Epoch - 1 | Loss: 1073.1612548828125\n",
      "Epoch - 1 | Loss: 604.2984008789062\n",
      "Epoch - 1 | Loss: 1311.047119140625\n",
      "Epoch - 1 | Loss: 774.1370239257812\n",
      "Epoch - 1 | Loss: 1340.9544677734375\n",
      "Epoch - 1 | Loss: 608.4012451171875\n",
      "Epoch - 2 | Loss: 833.9857177734375\n",
      "Epoch - 2 | Loss: 1266.3985595703125\n",
      "Epoch - 2 | Loss: 952.998291015625\n",
      "Epoch - 2 | Loss: 656.2217407226562\n",
      "Epoch - 2 | Loss: 1069.0675048828125\n",
      "Epoch - 2 | Loss: 1094.872314453125\n",
      "Epoch - 2 | Loss: 660.0144653320312\n",
      "Epoch - 2 | Loss: 1245.4375\n",
      "Epoch - 2 | Loss: 884.9662475585938\n",
      "Epoch - 2 | Loss: 944.98291015625\n",
      "Epoch - 2 | Loss: 259.3304748535156\n",
      "Epoch - 2 | Loss: 1205.840576171875\n",
      "Epoch - 2 | Loss: 283.37353515625\n",
      "Epoch - 2 | Loss: 495.8550720214844\n",
      "Epoch - 2 | Loss: 451.16571044921875\n",
      "Epoch - 2 | Loss: 829.08203125\n",
      "Epoch - 2 | Loss: 1265.907470703125\n",
      "Epoch - 2 | Loss: 801.3455810546875\n",
      "Epoch - 2 | Loss: 868.7618408203125\n",
      "Epoch - 2 | Loss: 779.5465087890625\n",
      "Epoch - 2 | Loss: 805.2644653320312\n",
      "Epoch - 2 | Loss: 1105.22998046875\n",
      "Epoch - 2 | Loss: 822.6967163085938\n",
      "Epoch - 2 | Loss: 801.24169921875\n",
      "Epoch - 2 | Loss: 404.4805603027344\n",
      "Epoch - 2 | Loss: 1071.2391357421875\n",
      "Epoch - 2 | Loss: 385.85321044921875\n",
      "Epoch - 2 | Loss: 266.8304443359375\n",
      "Epoch - 2 | Loss: 1119.6634521484375\n",
      "Epoch - 2 | Loss: 716.5518188476562\n",
      "Epoch - 2 | Loss: 1022.7838134765625\n",
      "Epoch - 2 | Loss: 1002.36572265625\n",
      "Epoch - 2 | Loss: 668.4581298828125\n",
      "Epoch - 2 | Loss: 918.2390747070312\n",
      "Epoch - 2 | Loss: 617.5933227539062\n",
      "Epoch - 2 | Loss: 504.2737121582031\n",
      "Epoch - 2 | Loss: 195.89234924316406\n",
      "Epoch - 2 | Loss: 471.54205322265625\n",
      "Epoch - 2 | Loss: 245.92066955566406\n",
      "Epoch - 2 | Loss: 267.3440246582031\n",
      "Epoch - 2 | Loss: 577.9033203125\n",
      "Epoch - 2 | Loss: 146.86672973632812\n",
      "Epoch - 2 | Loss: 173.95774841308594\n",
      "Epoch - 2 | Loss: 853.9230346679688\n",
      "Epoch - 2 | Loss: 637.6742553710938\n",
      "Epoch - 2 | Loss: 123.41778564453125\n",
      "Epoch - 2 | Loss: 305.458251953125\n",
      "Epoch - 2 | Loss: 574.463134765625\n",
      "Epoch - 2 | Loss: 3.64278244972229\n",
      "Epoch - 2 | Loss: 447.32061767578125\n",
      "Epoch - 2 | Loss: 726.4491577148438\n",
      "Epoch - 2 | Loss: 1096.6329345703125\n",
      "Epoch - 2 | Loss: 196.90060424804688\n",
      "Epoch - 2 | Loss: 122.78182983398438\n",
      "Epoch - 2 | Loss: 0.3247518241405487\n",
      "Epoch - 2 | Loss: 388.7191467285156\n",
      "Epoch - 2 | Loss: 378.9725036621094\n",
      "Epoch - 2 | Loss: 151.85552978515625\n",
      "Epoch - 2 | Loss: 728.891845703125\n",
      "Epoch - 2 | Loss: 308.19384765625\n",
      "Epoch - 2 | Loss: 628.9472045898438\n",
      "Epoch - 2 | Loss: 505.6562194824219\n",
      "Epoch - 2 | Loss: 1073.302978515625\n",
      "Epoch - 2 | Loss: 96.90144348144531\n",
      "Epoch - 2 | Loss: 82.4161605834961\n",
      "Epoch - 2 | Loss: 468.3858337402344\n",
      "Epoch - 2 | Loss: 677.0457763671875\n",
      "Epoch - 2 | Loss: 462.1374816894531\n",
      "Epoch - 2 | Loss: 432.4172058105469\n",
      "Epoch - 2 | Loss: 633.9567260742188\n",
      "Epoch - 2 | Loss: 53.88764190673828\n",
      "Epoch - 2 | Loss: 240.68194580078125\n",
      "Epoch - 2 | Loss: 618.8622436523438\n",
      "Epoch - 2 | Loss: 647.1751098632812\n",
      "Epoch - 2 | Loss: 321.8814697265625\n",
      "Epoch - 2 | Loss: 164.5528564453125\n",
      "Epoch - 2 | Loss: 172.8392791748047\n",
      "Epoch - 2 | Loss: 388.56378173828125\n",
      "Epoch - 2 | Loss: 643.8755493164062\n",
      "Epoch - 2 | Loss: 210.40435791015625\n",
      "Epoch - 2 | Loss: 404.5057067871094\n",
      "Epoch - 2 | Loss: 294.629150390625\n",
      "Epoch - 2 | Loss: 444.1971435546875\n",
      "Epoch - 2 | Loss: 149.185546875\n",
      "Epoch - 2 | Loss: 384.09490966796875\n",
      "Epoch - 2 | Loss: 251.41827392578125\n",
      "Epoch - 2 | Loss: 544.7390747070312\n",
      "Epoch - 2 | Loss: 474.18060302734375\n",
      "Epoch - 2 | Loss: 209.24461364746094\n",
      "Epoch - 2 | Loss: 312.9743957519531\n",
      "Epoch - 2 | Loss: 24.022838592529297\n",
      "Epoch - 2 | Loss: 492.56060791015625\n",
      "Epoch - 2 | Loss: 272.6640625\n",
      "Epoch - 2 | Loss: 327.32635498046875\n",
      "Epoch - 2 | Loss: 624.1919555664062\n",
      "Epoch - 2 | Loss: 326.58721923828125\n",
      "Epoch - 2 | Loss: 405.6885681152344\n",
      "Epoch - 2 | Loss: 551.3632202148438\n",
      "Epoch - 2 | Loss: 208.654052734375\n",
      "Epoch - 2 | Loss: 375.64373779296875\n",
      "Epoch - 2 | Loss: 163.3586883544922\n",
      "Epoch - 2 | Loss: 241.1094207763672\n",
      "Epoch - 2 | Loss: 115.30953979492188\n",
      "Epoch - 2 | Loss: 572.4176635742188\n",
      "Epoch - 2 | Loss: 743.3897705078125\n",
      "Epoch - 2 | Loss: 156.58139038085938\n",
      "Epoch - 2 | Loss: 34.531761169433594\n",
      "Epoch - 2 | Loss: 8.137043952941895\n",
      "Epoch - 2 | Loss: 193.3319091796875\n",
      "Epoch - 2 | Loss: 450.5648498535156\n",
      "Epoch - 2 | Loss: 161.05543518066406\n",
      "Epoch - 2 | Loss: 207.7973175048828\n",
      "Epoch - 2 | Loss: 265.9028015136719\n",
      "Epoch - 2 | Loss: 154.56683349609375\n",
      "Epoch - 2 | Loss: 288.551025390625\n",
      "Epoch - 2 | Loss: 47.759803771972656\n",
      "Epoch - 2 | Loss: 271.8284606933594\n",
      "Epoch - 2 | Loss: 51.91848373413086\n",
      "Epoch - 2 | Loss: 239.71531677246094\n",
      "Epoch - 2 | Loss: 296.666015625\n",
      "Epoch - 2 | Loss: 162.43150329589844\n",
      "Epoch - 2 | Loss: 393.66693115234375\n",
      "Epoch - 2 | Loss: 65.90855407714844\n",
      "Epoch - 2 | Loss: 14.487579345703125\n",
      "Epoch - 2 | Loss: 187.952880859375\n",
      "Epoch - 2 | Loss: 24.69143295288086\n",
      "Epoch - 2 | Loss: 301.04522705078125\n",
      "Epoch - 2 | Loss: 66.93893432617188\n",
      "Epoch - 2 | Loss: 276.04168701171875\n",
      "Epoch - 2 | Loss: 82.56674194335938\n",
      "Epoch - 3 | Loss: 92.95033264160156\n",
      "Epoch - 3 | Loss: 324.0384521484375\n",
      "Epoch - 3 | Loss: 216.70123291015625\n",
      "Epoch - 3 | Loss: 115.0674057006836\n",
      "Epoch - 3 | Loss: 215.90052795410156\n",
      "Epoch - 3 | Loss: 312.77978515625\n",
      "Epoch - 3 | Loss: 63.45167922973633\n",
      "Epoch - 3 | Loss: 265.53070068359375\n",
      "Epoch - 3 | Loss: 176.42758178710938\n",
      "Epoch - 3 | Loss: 154.7376251220703\n",
      "Epoch - 3 | Loss: 15.096443176269531\n",
      "Epoch - 3 | Loss: 258.14239501953125\n",
      "Epoch - 3 | Loss: 2.209023952484131\n",
      "Epoch - 3 | Loss: 55.27170181274414\n",
      "Epoch - 3 | Loss: 47.41554641723633\n",
      "Epoch - 3 | Loss: 124.34388732910156\n",
      "Epoch - 3 | Loss: 309.27752685546875\n",
      "Epoch - 3 | Loss: 151.08407592773438\n",
      "Epoch - 3 | Loss: 148.47128295898438\n",
      "Epoch - 3 | Loss: 132.72727966308594\n",
      "Epoch - 3 | Loss: 127.46868896484375\n",
      "Epoch - 3 | Loss: 239.9329376220703\n",
      "Epoch - 3 | Loss: 182.88160705566406\n",
      "Epoch - 3 | Loss: 116.45293426513672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 3 | Loss: 33.00523376464844\n",
      "Epoch - 3 | Loss: 284.3290710449219\n",
      "Epoch - 3 | Loss: 23.786495208740234\n",
      "Epoch - 3 | Loss: 5.41860294342041\n",
      "Epoch - 3 | Loss: 290.885009765625\n",
      "Epoch - 3 | Loss: 169.48416137695312\n",
      "Epoch - 3 | Loss: 367.5742492675781\n",
      "Epoch - 3 | Loss: 230.11634826660156\n",
      "Epoch - 3 | Loss: 167.77622985839844\n",
      "Epoch - 3 | Loss: 316.4964904785156\n",
      "Epoch - 3 | Loss: 69.01498413085938\n",
      "Epoch - 3 | Loss: 80.25724792480469\n",
      "Epoch - 3 | Loss: 2.340184211730957\n",
      "Epoch - 3 | Loss: 67.20448303222656\n",
      "Epoch - 3 | Loss: 5.132226943969727\n",
      "Epoch - 3 | Loss: 5.462700843811035\n",
      "Epoch - 3 | Loss: 73.47876739501953\n",
      "Epoch - 3 | Loss: 34.417442321777344\n",
      "Epoch - 3 | Loss: 0.38786423206329346\n",
      "Epoch - 3 | Loss: 200.16705322265625\n",
      "Epoch - 3 | Loss: 112.1894760131836\n",
      "Epoch - 3 | Loss: 5.976176738739014\n",
      "Epoch - 3 | Loss: 26.956600189208984\n",
      "Epoch - 3 | Loss: 66.5357437133789\n",
      "Epoch - 3 | Loss: 109.17923736572266\n",
      "Epoch - 3 | Loss: 24.686580657958984\n",
      "Epoch - 3 | Loss: 139.38487243652344\n",
      "Epoch - 3 | Loss: 411.5534973144531\n",
      "Epoch - 3 | Loss: 1.9002044200897217\n",
      "Epoch - 3 | Loss: 11.98733139038086\n",
      "Epoch - 3 | Loss: 172.6768341064453\n",
      "Epoch - 3 | Loss: 76.30203247070312\n",
      "Epoch - 3 | Loss: 47.29762649536133\n",
      "Epoch - 3 | Loss: 0.09829625487327576\n",
      "Epoch - 3 | Loss: 161.9119873046875\n",
      "Epoch - 3 | Loss: 49.431129455566406\n",
      "Epoch - 3 | Loss: 130.1162872314453\n",
      "Epoch - 3 | Loss: 86.91935729980469\n",
      "Epoch - 3 | Loss: 418.322998046875\n",
      "Epoch - 3 | Loss: 1.7239282131195068\n",
      "Epoch - 3 | Loss: 2.3873493671417236\n",
      "Epoch - 3 | Loss: 75.14677429199219\n",
      "Epoch - 3 | Loss: 239.55538940429688\n",
      "Epoch - 3 | Loss: 112.0438232421875\n",
      "Epoch - 3 | Loss: 66.67372131347656\n",
      "Epoch - 3 | Loss: 143.6170196533203\n",
      "Epoch - 3 | Loss: 14.543971061706543\n",
      "Epoch - 3 | Loss: 9.868030548095703\n",
      "Epoch - 3 | Loss: 141.104248046875\n",
      "Epoch - 3 | Loss: 159.63209533691406\n",
      "Epoch - 3 | Loss: 27.2481746673584\n",
      "Epoch - 3 | Loss: 0.06674688309431076\n",
      "Epoch - 3 | Loss: 7.1644606590271\n",
      "Epoch - 3 | Loss: 53.38855743408203\n",
      "Epoch - 3 | Loss: 167.7945098876953\n",
      "Epoch - 3 | Loss: 4.165184020996094\n",
      "Epoch - 3 | Loss: 69.91244506835938\n",
      "Epoch - 3 | Loss: 48.83884811401367\n",
      "Epoch - 3 | Loss: 82.08272552490234\n",
      "Epoch - 3 | Loss: 4.9445600509643555\n",
      "Epoch - 3 | Loss: 57.74014663696289\n",
      "Epoch - 3 | Loss: 15.949380874633789\n",
      "Epoch - 3 | Loss: 146.05882263183594\n",
      "Epoch - 3 | Loss: 116.08174896240234\n",
      "Epoch - 3 | Loss: 9.86419677734375\n",
      "Epoch - 3 | Loss: 27.59832000732422\n",
      "Epoch - 3 | Loss: 36.14250564575195\n",
      "Epoch - 3 | Loss: 112.94088745117188\n",
      "Epoch - 3 | Loss: 32.2315559387207\n",
      "Epoch - 3 | Loss: 43.75325012207031\n",
      "Epoch - 3 | Loss: 176.7322235107422\n",
      "Epoch - 3 | Loss: 60.17477798461914\n",
      "Epoch - 3 | Loss: 73.95236206054688\n",
      "Epoch - 3 | Loss: 192.51817321777344\n",
      "Epoch - 3 | Loss: 15.301794052124023\n",
      "Epoch - 3 | Loss: 71.27240753173828\n",
      "Epoch - 3 | Loss: 9.59998893737793\n",
      "Epoch - 3 | Loss: 26.85983657836914\n",
      "Epoch - 3 | Loss: 4.568567276000977\n",
      "Epoch - 3 | Loss: 184.94854736328125\n",
      "Epoch - 3 | Loss: 356.8921813964844\n",
      "Epoch - 3 | Loss: 5.087834358215332\n",
      "Epoch - 3 | Loss: 20.36049461364746\n",
      "Epoch - 3 | Loss: 33.44230651855469\n",
      "Epoch - 3 | Loss: 13.308034896850586\n",
      "Epoch - 3 | Loss: 123.5511474609375\n",
      "Epoch - 3 | Loss: 9.127615928649902\n",
      "Epoch - 3 | Loss: 17.853126525878906\n",
      "Epoch - 3 | Loss: 39.77901077270508\n",
      "Epoch - 3 | Loss: 3.9151580333709717\n",
      "Epoch - 3 | Loss: 51.584617614746094\n",
      "Epoch - 3 | Loss: 3.9306015968322754\n",
      "Epoch - 3 | Loss: 41.92353057861328\n",
      "Epoch - 3 | Loss: 1.1237242221832275\n",
      "Epoch - 3 | Loss: 35.09237289428711\n",
      "Epoch - 3 | Loss: 81.04766082763672\n",
      "Epoch - 3 | Loss: 25.84984588623047\n",
      "Epoch - 3 | Loss: 128.8448028564453\n",
      "Epoch - 3 | Loss: 0.9816220998764038\n",
      "Epoch - 3 | Loss: 132.6658477783203\n",
      "Epoch - 3 | Loss: 23.071313858032227\n",
      "Epoch - 3 | Loss: 17.458181381225586\n",
      "Epoch - 3 | Loss: 73.59077453613281\n",
      "Epoch - 3 | Loss: 0.868608295917511\n",
      "Epoch - 3 | Loss: 54.124473571777344\n",
      "Epoch - 3 | Loss: 3.593991279602051\n",
      "Epoch - 4 | Loss: 0.6153686046600342\n",
      "Epoch - 4 | Loss: 98.53218841552734\n",
      "Epoch - 4 | Loss: 53.63959884643555\n",
      "Epoch - 4 | Loss: 15.395828247070312\n",
      "Epoch - 4 | Loss: 42.08759689331055\n",
      "Epoch - 4 | Loss: 114.08098602294922\n",
      "Epoch - 4 | Loss: 0.005924836732447147\n",
      "Epoch - 4 | Loss: 59.22370529174805\n",
      "Epoch - 4 | Loss: 34.16934585571289\n",
      "Epoch - 4 | Loss: 17.571659088134766\n",
      "Epoch - 4 | Loss: 165.71160888671875\n",
      "Epoch - 4 | Loss: 59.285606384277344\n",
      "Epoch - 4 | Loss: 28.92516326904297\n",
      "Epoch - 4 | Loss: 0.6683703660964966\n",
      "Epoch - 4 | Loss: 0.24908530712127686\n",
      "Epoch - 4 | Loss: 11.032075881958008\n",
      "Epoch - 4 | Loss: 92.5796890258789\n",
      "Epoch - 4 | Loss: 27.24809455871582\n",
      "Epoch - 4 | Loss: 20.883852005004883\n",
      "Epoch - 4 | Loss: 18.624975204467773\n",
      "Epoch - 4 | Loss: 14.452608108520508\n",
      "Epoch - 4 | Loss: 59.716392517089844\n",
      "Epoch - 4 | Loss: 47.77968215942383\n",
      "Epoch - 4 | Loss: 10.05687141418457\n",
      "Epoch - 4 | Loss: 0.24043074250221252\n",
      "Epoch - 4 | Loss: 99.84182739257812\n",
      "Epoch - 4 | Loss: 2.2529077529907227\n",
      "Epoch - 4 | Loss: 13.750764846801758\n",
      "Epoch - 4 | Loss: 100.05799102783203\n",
      "Epoch - 4 | Loss: 50.71774673461914\n",
      "Epoch - 4 | Loss: 187.4464569091797\n",
      "Epoch - 4 | Loss: 66.05790710449219\n",
      "Epoch - 4 | Loss: 55.56795120239258\n",
      "Epoch - 4 | Loss: 155.4559326171875\n",
      "Epoch - 4 | Loss: 1.646453619003296\n",
      "Epoch - 4 | Loss: 10.487874031066895\n",
      "Epoch - 4 | Loss: 14.013933181762695\n",
      "Epoch - 4 | Loss: 6.206340789794922\n",
      "Epoch - 4 | Loss: 96.57539367675781\n",
      "Epoch - 4 | Loss: 12.627180099487305\n",
      "Epoch - 4 | Loss: 4.350498676300049\n",
      "Epoch - 4 | Loss: 179.2916717529297\n",
      "Epoch - 4 | Loss: 21.333253860473633\n",
      "Epoch - 4 | Loss: 62.07980728149414\n",
      "Epoch - 4 | Loss: 20.35863494873047\n",
      "Epoch - 4 | Loss: 64.80831909179688\n",
      "Epoch - 4 | Loss: 0.01571955718100071\n",
      "Epoch - 4 | Loss: 2.738718032836914\n",
      "Epoch - 4 | Loss: 240.7597198486328\n",
      "Epoch - 4 | Loss: 2.7112877368927\n",
      "Epoch - 4 | Loss: 31.73674201965332\n",
      "Epoch - 4 | Loss: 227.2481689453125\n",
      "Epoch - 4 | Loss: 14.04857063293457\n",
      "Epoch - 4 | Loss: 87.19007110595703\n",
      "Epoch - 4 | Loss: 331.37957763671875\n",
      "Epoch - 4 | Loss: 18.72183609008789\n",
      "Epoch - 4 | Loss: 3.3825831413269043\n",
      "Epoch - 4 | Loss: 20.04979133605957\n",
      "Epoch - 4 | Loss: 49.669952392578125\n",
      "Epoch - 4 | Loss: 8.162549018859863\n",
      "Epoch - 4 | Loss: 36.007781982421875\n",
      "Epoch - 4 | Loss: 17.073013305664062\n",
      "Epoch - 4 | Loss: 243.73500061035156\n",
      "Epoch - 4 | Loss: 32.38502883911133\n",
      "Epoch - 4 | Loss: 32.52972412109375\n",
      "Epoch - 4 | Loss: 12.984115600585938\n",
      "Epoch - 4 | Loss: 129.3067169189453\n",
      "Epoch - 4 | Loss: 40.24950408935547\n",
      "Epoch - 4 | Loss: 10.67811393737793\n",
      "Epoch - 4 | Loss: 47.30581283569336\n",
      "Epoch - 4 | Loss: 65.96151733398438\n",
      "Epoch - 4 | Loss: 2.6452388763427734\n",
      "Epoch - 4 | Loss: 47.35536193847656\n",
      "Epoch - 4 | Loss: 59.63835906982422\n",
      "Epoch - 4 | Loss: 0.12295329570770264\n",
      "Epoch - 4 | Loss: 20.63218879699707\n",
      "Epoch - 4 | Loss: 1.7231769561767578\n",
      "Epoch - 4 | Loss: 6.716817855834961\n",
      "Epoch - 4 | Loss: 67.9614486694336\n",
      "Epoch - 4 | Loss: 7.1524577140808105\n",
      "Epoch - 4 | Loss: 15.419726371765137\n",
      "Epoch - 4 | Loss: 9.968128204345703\n",
      "Epoch - 4 | Loss: 20.6719913482666\n",
      "Epoch - 4 | Loss: 2.3118860721588135\n",
      "Epoch - 4 | Loss: 9.685015678405762\n",
      "Epoch - 4 | Loss: 0.1862148493528366\n",
      "Epoch - 4 | Loss: 62.36567306518555\n",
      "Epoch - 4 | Loss: 44.74174118041992\n",
      "Epoch - 4 | Loss: 1.1141045093536377\n",
      "Epoch - 4 | Loss: 0.4290134012699127\n",
      "Epoch - 4 | Loss: 100.74877166748047\n",
      "Epoch - 4 | Loss: 40.60541915893555\n",
      "Epoch - 4 | Loss: 2.893700122833252\n",
      "Epoch - 4 | Loss: 5.824125289916992\n",
      "Epoch - 4 | Loss: 81.4659423828125\n",
      "Epoch - 4 | Loss: 15.9986572265625\n",
      "Epoch - 4 | Loss: 19.399511337280273\n",
      "Epoch - 4 | Loss: 107.98062896728516\n",
      "Epoch - 4 | Loss: 0.00988861732184887\n",
      "Epoch - 4 | Loss: 20.170839309692383\n",
      "Epoch - 4 | Loss: 0.15357893705368042\n",
      "Epoch - 4 | Loss: 2.135943651199341\n",
      "Epoch - 4 | Loss: 0.9023057818412781\n",
      "Epoch - 4 | Loss: 98.03450012207031\n",
      "Epoch - 4 | Loss: 252.74673461914062\n",
      "Epoch - 4 | Loss: 1.9761016368865967\n",
      "Epoch - 4 | Loss: 67.47112274169922\n",
      "Epoch - 4 | Loss: 78.38865661621094\n",
      "Epoch - 4 | Loss: 9.153247810900211e-05\n",
      "Epoch - 4 | Loss: 56.80790328979492\n",
      "Epoch - 4 | Loss: 0.1545671820640564\n",
      "Epoch - 4 | Loss: 0.40400323271751404\n",
      "Epoch - 4 | Loss: 7.799950122833252\n",
      "Epoch - 4 | Loss: 2.8443613052368164\n",
      "Epoch - 4 | Loss: 14.087574005126953\n",
      "Epoch - 4 | Loss: 25.860048294067383\n",
      "Epoch - 4 | Loss: 8.946703910827637\n",
      "Epoch - 4 | Loss: 15.434260368347168\n",
      "Epoch - 4 | Loss: 6.841166973114014\n",
      "Epoch - 4 | Loss: 38.003379821777344\n",
      "Epoch - 4 | Loss: 5.984311580657959\n",
      "Epoch - 4 | Loss: 71.1374740600586\n",
      "Epoch - 4 | Loss: 16.921466827392578\n",
      "Epoch - 4 | Loss: 200.3875274658203\n",
      "Epoch - 4 | Loss: 3.1170005798339844\n",
      "Epoch - 4 | Loss: 53.140220642089844\n",
      "Epoch - 4 | Loss: 31.402551651000977\n",
      "Epoch - 4 | Loss: 16.109500885009766\n",
      "Epoch - 4 | Loss: 17.945117950439453\n",
      "Epoch - 4 | Loss: 0.271890252828598\n",
      "Epoch - 5 | Loss: 4.769581317901611\n",
      "Epoch - 5 | Loss: 52.24470901489258\n",
      "Epoch - 5 | Loss: 23.607223510742188\n",
      "Epoch - 5 | Loss: 2.7622270584106445\n",
      "Epoch - 5 | Loss: 14.183436393737793\n",
      "Epoch - 5 | Loss: 69.94013214111328\n",
      "Epoch - 5 | Loss: 7.468631267547607\n",
      "Epoch - 5 | Loss: 23.640300750732422\n",
      "Epoch - 5 | Loss: 11.558195114135742\n",
      "Epoch - 5 | Loss: 2.205385446548462\n",
      "Epoch - 5 | Loss: 250.16522216796875\n",
      "Epoch - 5 | Loss: 24.673391342163086\n",
      "Epoch - 5 | Loss: 57.97279739379883\n",
      "Epoch - 5 | Loss: 1.7718791961669922\n",
      "Epoch - 5 | Loss: 2.460552930831909\n",
      "Epoch - 5 | Loss: 0.6313065886497498\n",
      "Epoch - 5 | Loss: 49.83031463623047\n",
      "Epoch - 5 | Loss: 8.70486831665039\n",
      "Epoch - 5 | Loss: 4.54615592956543\n",
      "Epoch - 5 | Loss: 4.059484481811523\n",
      "Epoch - 5 | Loss: 2.005229949951172\n",
      "Epoch - 5 | Loss: 27.676612854003906\n",
      "Epoch - 5 | Loss: 23.19122886657715\n",
      "Epoch - 5 | Loss: 0.5771394968032837\n",
      "Epoch - 5 | Loss: 6.050601005554199\n",
      "Epoch - 5 | Loss: 61.262939453125\n",
      "Epoch - 5 | Loss: 12.30151081085205\n",
      "Epoch - 5 | Loss: 31.39459991455078\n",
      "Epoch - 5 | Loss: 60.75117492675781\n",
      "Epoch - 5 | Loss: 27.861068725585938\n",
      "Epoch - 5 | Loss: 143.53775024414062\n",
      "Epoch - 5 | Loss: 35.20192337036133\n",
      "Epoch - 5 | Loss: 32.975650787353516\n",
      "Epoch - 5 | Loss: 116.90998840332031\n",
      "Epoch - 5 | Loss: 0.8115003108978271\n",
      "Epoch - 5 | Loss: 2.134873390197754\n",
      "Epoch - 5 | Loss: 28.953771591186523\n",
      "Epoch - 5 | Loss: 0.5205022692680359\n",
      "Epoch - 5 | Loss: 148.09176635742188\n",
      "Epoch - 5 | Loss: 28.87996482849121\n",
      "Epoch - 5 | Loss: 0.007489209994673729\n",
      "Epoch - 5 | Loss: 246.57183837890625\n",
      "Epoch - 5 | Loss: 38.7387809753418\n",
      "Epoch - 5 | Loss: 35.608673095703125\n",
      "Epoch - 5 | Loss: 7.100522041320801\n",
      "Epoch - 5 | Loss: 95.02218627929688\n",
      "Epoch - 5 | Loss: 1.9684087038040161\n",
      "Epoch - 5 | Loss: 0.08910684287548065\n",
      "Epoch - 5 | Loss: 290.1322326660156\n",
      "Epoch - 5 | Loss: 13.082003593444824\n",
      "Epoch - 5 | Loss: 14.470829010009766\n",
      "Epoch - 5 | Loss: 183.2450714111328\n",
      "Epoch - 5 | Loss: 27.62129020690918\n",
      "Epoch - 5 | Loss: 122.28929138183594\n",
      "Epoch - 5 | Loss: 387.31292724609375\n",
      "Epoch - 5 | Loss: 9.29391098022461\n",
      "Epoch - 5 | Loss: 0.14906790852546692\n",
      "Epoch - 5 | Loss: 34.254356384277344\n",
      "Epoch - 5 | Loss: 29.454999923706055\n",
      "Epoch - 5 | Loss: 2.791391611099243\n",
      "Epoch - 5 | Loss: 19.990257263183594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 5 | Loss: 7.122251033782959\n",
      "Epoch - 5 | Loss: 203.126220703125\n",
      "Epoch - 5 | Loss: 47.85517883300781\n",
      "Epoch - 5 | Loss: 47.13856506347656\n",
      "Epoch - 5 | Loss: 4.806575775146484\n",
      "Epoch - 5 | Loss: 104.66678619384766\n",
      "Epoch - 5 | Loss: 26.716812133789062\n",
      "Epoch - 5 | Loss: 3.6590514183044434\n",
      "Epoch - 5 | Loss: 29.896879196166992\n",
      "Epoch - 5 | Loss: 86.67733001708984\n",
      "Epoch - 5 | Loss: 8.63616943359375\n",
      "Epoch - 5 | Loss: 30.35390281677246\n",
      "Epoch - 5 | Loss: 40.65969467163086\n",
      "Epoch - 5 | Loss: 0.9641186594963074\n",
      "Epoch - 5 | Loss: 34.26775360107422\n",
      "Epoch - 5 | Loss: 5.761563777923584\n",
      "Epoch - 5 | Loss: 1.7151942253112793\n",
      "Epoch - 5 | Loss: 48.53083801269531\n",
      "Epoch - 5 | Loss: 15.611699104309082\n",
      "Epoch - 5 | Loss: 7.445796966552734\n",
      "Epoch - 5 | Loss: 4.51171875\n",
      "Epoch - 5 | Loss: 11.102534294128418\n",
      "Epoch - 5 | Loss: 6.384227275848389\n",
      "Epoch - 5 | Loss: 3.6435396671295166\n",
      "Epoch - 5 | Loss: 2.612335205078125\n",
      "Epoch - 5 | Loss: 45.942317962646484\n",
      "Epoch - 5 | Loss: 31.346824645996094\n",
      "Epoch - 5 | Loss: 4.727320194244385\n",
      "Epoch - 5 | Loss: 0.3240739107131958\n",
      "Epoch - 5 | Loss: 123.37922668457031\n",
      "Epoch - 5 | Loss: 27.501811981201172\n",
      "Epoch - 5 | Loss: 0.42158007621765137\n",
      "Epoch - 5 | Loss: 1.7017515897750854\n",
      "Epoch - 5 | Loss: 62.438236236572266\n",
      "Epoch - 5 | Loss: 9.068243980407715\n",
      "Epoch - 5 | Loss: 10.903922080993652\n",
      "Epoch - 5 | Loss: 89.80220031738281\n",
      "Epoch - 5 | Loss: 0.8133983612060547\n",
      "Epoch - 5 | Loss: 11.92776107788086\n",
      "Epoch - 5 | Loss: 1.7124176025390625\n",
      "Epoch - 5 | Loss: 0.2347891628742218\n",
      "Epoch - 5 | Loss: 3.098493814468384\n",
      "Epoch - 5 | Loss: 79.77161407470703\n",
      "Epoch - 5 | Loss: 228.392822265625\n",
      "Epoch - 5 | Loss: 5.6053466796875\n",
      "Epoch - 5 | Loss: 84.40889739990234\n",
      "Epoch - 5 | Loss: 93.33277130126953\n",
      "Epoch - 5 | Loss: 0.8926207423210144\n",
      "Epoch - 5 | Loss: 43.566123962402344\n",
      "Epoch - 5 | Loss: 1.65339195728302\n",
      "Epoch - 5 | Loss: 0.09085988998413086\n",
      "Epoch - 5 | Loss: 3.5231821537017822\n",
      "Epoch - 5 | Loss: 6.97048282623291\n",
      "Epoch - 5 | Loss: 8.196456909179688\n",
      "Epoch - 5 | Loss: 34.68836212158203\n",
      "Epoch - 5 | Loss: 4.369870662689209\n",
      "Epoch - 5 | Loss: 21.797517776489258\n",
      "Epoch - 5 | Loss: 3.1140918731689453\n",
      "Epoch - 5 | Loss: 29.556201934814453\n",
      "Epoch - 5 | Loss: 3.135251760482788\n",
      "Epoch - 5 | Loss: 59.11619186401367\n",
      "Epoch - 5 | Loss: 24.120649337768555\n",
      "Epoch - 5 | Loss: 219.89230346679688\n",
      "Epoch - 5 | Loss: 0.9871630668640137\n",
      "Epoch - 5 | Loss: 65.24821472167969\n",
      "Epoch - 5 | Loss: 23.56209373474121\n",
      "Epoch - 5 | Loss: 22.918315887451172\n",
      "Epoch - 5 | Loss: 11.946581840515137\n",
      "Epoch - 5 | Loss: 1.2618855237960815\n",
      "Epoch - 6 | Loss: 8.525720596313477\n",
      "Epoch - 6 | Loss: 43.058597564697266\n",
      "Epoch - 6 | Loss: 18.079008102416992\n",
      "Epoch - 6 | Loss: 1.2243815660476685\n",
      "Epoch - 6 | Loss: 9.606585502624512\n",
      "Epoch - 6 | Loss: 60.777400970458984\n",
      "Epoch - 6 | Loss: 11.439033508300781\n",
      "Epoch - 6 | Loss: 17.39200210571289\n",
      "Epoch - 6 | Loss: 7.8557047843933105\n",
      "Epoch - 6 | Loss: 0.6800535917282104\n",
      "Epoch - 6 | Loss: 273.3907165527344\n",
      "Epoch - 6 | Loss: 18.5207462310791\n",
      "Epoch - 6 | Loss: 66.51177978515625\n",
      "Epoch - 6 | Loss: 3.4192912578582764\n",
      "Epoch - 6 | Loss: 4.263274192810059\n",
      "Epoch - 6 | Loss: 0.03667433187365532\n",
      "Epoch - 6 | Loss: 41.6077766418457\n",
      "Epoch - 6 | Loss: 5.822210311889648\n",
      "Epoch - 6 | Loss: 2.4226787090301514\n",
      "Epoch - 6 | Loss: 2.168626546859741\n",
      "Epoch - 6 | Loss: 0.7311220765113831\n",
      "Epoch - 6 | Loss: 21.920045852661133\n",
      "Epoch - 6 | Loss: 18.69550323486328\n",
      "Epoch - 6 | Loss: 0.03766866400837898\n",
      "Epoch - 6 | Loss: 8.537443161010742\n",
      "Epoch - 6 | Loss: 53.57826232910156\n",
      "Epoch - 6 | Loss: 15.823943138122559\n",
      "Epoch - 6 | Loss: 36.57097244262695\n",
      "Epoch - 6 | Loss: 52.964508056640625\n",
      "Epoch - 6 | Loss: 23.493520736694336\n",
      "Epoch - 6 | Loss: 134.0978546142578\n",
      "Epoch - 6 | Loss: 29.35388946533203\n",
      "Epoch - 6 | Loss: 28.50118064880371\n",
      "Epoch - 6 | Loss: 108.57946014404297\n",
      "Epoch - 6 | Loss: 2.0194945335388184\n",
      "Epoch - 6 | Loss: 1.071990728378296\n",
      "Epoch - 6 | Loss: 33.35020065307617\n",
      "Epoch - 6 | Loss: 0.08668440580368042\n",
      "Epoch - 6 | Loss: 162.1884002685547\n",
      "Epoch - 6 | Loss: 33.79597854614258\n",
      "Epoch - 6 | Loss: 0.15540216863155365\n",
      "Epoch - 6 | Loss: 264.2747802734375\n",
      "Epoch - 6 | Loss: 43.63393020629883\n",
      "Epoch - 6 | Loss: 30.445098876953125\n",
      "Epoch - 6 | Loss: 4.9890570640563965\n",
      "Epoch - 6 | Loss: 102.84852600097656\n",
      "Epoch - 6 | Loss: 3.07688307762146\n",
      "Epoch - 6 | Loss: 0.5514540076255798\n",
      "Epoch - 6 | Loss: 301.90069580078125\n",
      "Epoch - 6 | Loss: 16.440366744995117\n",
      "Epoch - 6 | Loss: 11.582901000976562\n",
      "Epoch - 6 | Loss: 174.34466552734375\n",
      "Epoch - 6 | Loss: 31.12888526916504\n",
      "Epoch - 6 | Loss: 130.5164031982422\n",
      "Epoch - 6 | Loss: 399.6119079589844\n",
      "Epoch - 6 | Loss: 7.757201671600342\n",
      "Epoch - 6 | Loss: 0.00849403440952301\n",
      "Epoch - 6 | Loss: 37.53118896484375\n",
      "Epoch - 6 | Loss: 26.123023986816406\n",
      "Epoch - 6 | Loss: 2.080292224884033\n",
      "Epoch - 6 | Loss: 17.481332778930664\n",
      "Epoch - 6 | Loss: 5.732975959777832\n",
      "Epoch - 6 | Loss: 195.98675537109375\n",
      "Epoch - 6 | Loss: 51.05604553222656\n",
      "Epoch - 6 | Loss: 50.13004684448242\n",
      "Epoch - 6 | Loss: 3.74226713180542\n",
      "Epoch - 6 | Loss: 100.46623992919922\n",
      "Epoch - 6 | Loss: 24.55809211730957\n",
      "Epoch - 6 | Loss: 2.779956817626953\n",
      "Epoch - 6 | Loss: 27.166194915771484\n",
      "Epoch - 6 | Loss: 90.75530242919922\n",
      "Epoch - 6 | Loss: 10.094941139221191\n",
      "Epoch - 6 | Loss: 27.677976608276367\n",
      "Epoch - 6 | Loss: 37.611202239990234\n",
      "Epoch - 6 | Loss: 1.4979307651519775\n",
      "Epoch - 6 | Loss: 37.1190071105957\n",
      "Epoch - 6 | Loss: 6.750176429748535\n",
      "Epoch - 6 | Loss: 1.1612021923065186\n",
      "Epoch - 6 | Loss: 45.370819091796875\n",
      "Epoch - 6 | Loss: 17.48905372619629\n",
      "Epoch - 6 | Loss: 6.311797618865967\n",
      "Epoch - 6 | Loss: 3.7530784606933594\n",
      "Epoch - 6 | Loss: 9.688102722167969\n",
      "Epoch - 6 | Loss: 7.340043067932129\n",
      "Epoch - 6 | Loss: 2.8584296703338623\n",
      "Epoch - 6 | Loss: 3.3539347648620605\n",
      "Epoch - 6 | Loss: 43.22817611694336\n",
      "Epoch - 6 | Loss: 29.160181045532227\n",
      "Epoch - 6 | Loss: 5.662425994873047\n",
      "Epoch - 6 | Loss: 0.6317673921585083\n",
      "Epoch - 6 | Loss: 127.81735229492188\n",
      "Epoch - 6 | Loss: 25.366859436035156\n",
      "Epoch - 6 | Loss: 0.20769371092319489\n",
      "Epoch - 6 | Loss: 1.2115412950515747\n",
      "Epoch - 6 | Loss: 59.2165412902832\n",
      "Epoch - 6 | Loss: 8.000664710998535\n",
      "Epoch - 6 | Loss: 9.592023849487305\n",
      "Epoch - 6 | Loss: 86.57550811767578\n",
      "Epoch - 6 | Loss: 1.1928201913833618\n",
      "Epoch - 6 | Loss: 10.591382026672363\n",
      "Epoch - 6 | Loss: 2.210759162902832\n",
      "Epoch - 6 | Loss: 0.08576811850070953\n",
      "Epoch - 6 | Loss: 3.689836263656616\n",
      "Epoch - 6 | Loss: 76.35782623291016\n",
      "Epoch - 6 | Loss: 223.62435913085938\n",
      "Epoch - 6 | Loss: 6.579628944396973\n",
      "Epoch - 6 | Loss: 88.17681884765625\n",
      "Epoch - 6 | Loss: 96.6381607055664\n",
      "Epoch - 6 | Loss: 1.3112794160842896\n",
      "Epoch - 6 | Loss: 41.01052474975586\n",
      "Epoch - 6 | Loss: 2.1723358631134033\n",
      "Epoch - 6 | Loss: 0.2491614669561386\n",
      "Epoch - 6 | Loss: 2.8340511322021484\n",
      "Epoch - 6 | Loss: 8.077457427978516\n",
      "Epoch - 6 | Loss: 7.152294635772705\n",
      "Epoch - 6 | Loss: 36.728702545166016\n",
      "Epoch - 6 | Loss: 3.6100058555603027\n",
      "Epoch - 6 | Loss: 23.283540725708008\n",
      "Epoch - 6 | Loss: 2.5148348808288574\n",
      "Epoch - 6 | Loss: 27.91844367980957\n",
      "Epoch - 6 | Loss: 2.6528632640838623\n",
      "Epoch - 6 | Loss: 56.73248291015625\n",
      "Epoch - 6 | Loss: 25.80401611328125\n",
      "Epoch - 6 | Loss: 224.14193725585938\n",
      "Epoch - 6 | Loss: 0.6916286945343018\n",
      "Epoch - 6 | Loss: 67.92372131347656\n",
      "Epoch - 6 | Loss: 22.09233856201172\n",
      "Epoch - 6 | Loss: 24.447439193725586\n",
      "Epoch - 6 | Loss: 10.891379356384277\n",
      "Epoch - 6 | Loss: 1.545096516609192\n",
      "Epoch - 7 | Loss: 9.390125274658203\n",
      "Epoch - 7 | Loss: 41.38013458251953\n",
      "Epoch - 7 | Loss: 17.097579956054688\n",
      "Epoch - 7 | Loss: 0.9990847110748291\n",
      "Epoch - 7 | Loss: 8.830427169799805\n",
      "Epoch - 7 | Loss: 59.08821487426758\n",
      "Epoch - 7 | Loss: 12.30474853515625\n",
      "Epoch - 7 | Loss: 16.290800094604492\n",
      "Epoch - 7 | Loss: 7.214457035064697\n",
      "Epoch - 7 | Loss: 0.4822295308113098\n",
      "Epoch - 7 | Loss: 278.12799072265625\n",
      "Epoch - 7 | Loss: 17.415555953979492\n",
      "Epoch - 7 | Loss: 68.25126647949219\n",
      "Epoch - 7 | Loss: 3.7990076541900635\n",
      "Epoch - 7 | Loss: 4.661677837371826\n",
      "Epoch - 7 | Loss: 0.0062691327184438705\n",
      "Epoch - 7 | Loss: 40.18143081665039\n",
      "Epoch - 7 | Loss: 5.359024524688721\n",
      "Epoch - 7 | Loss: 2.1086020469665527\n",
      "Epoch - 7 | Loss: 1.8889888525009155\n",
      "Epoch - 7 | Loss: 0.5677995681762695\n",
      "Epoch - 7 | Loss: 20.949798583984375\n",
      "Epoch - 7 | Loss: 17.926313400268555\n",
      "Epoch - 7 | Loss: 0.008067787624895573\n",
      "Epoch - 7 | Loss: 9.049483299255371\n",
      "Epoch - 7 | Loss: 52.19432067871094\n",
      "Epoch - 7 | Loss: 16.545185089111328\n",
      "Epoch - 7 | Loss: 37.610782623291016\n",
      "Epoch - 7 | Loss: 51.53356170654297\n",
      "Epoch - 7 | Loss: 22.689189910888672\n",
      "Epoch - 7 | Loss: 132.27597045898438\n",
      "Epoch - 7 | Loss: 28.24276351928711\n",
      "Epoch - 7 | Loss: 27.61315155029297\n",
      "Epoch - 7 | Loss: 106.83625793457031\n",
      "Epoch - 7 | Loss: 2.3592820167541504\n",
      "Epoch - 7 | Loss: 0.8803158402442932\n",
      "Epoch - 7 | Loss: 34.42634963989258\n",
      "Epoch - 7 | Loss: 0.037077225744724274\n",
      "Epoch - 7 | Loss: 165.6894073486328\n",
      "Epoch - 7 | Loss: 35.044029235839844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 7 | Loss: 0.25968989729881287\n",
      "Epoch - 7 | Loss: 268.5743103027344\n",
      "Epoch - 7 | Loss: 44.81203842163086\n",
      "Epoch - 7 | Loss: 29.34694480895996\n",
      "Epoch - 7 | Loss: 4.579205513000488\n",
      "Epoch - 7 | Loss: 104.55230712890625\n",
      "Epoch - 7 | Loss: 3.3351266384124756\n",
      "Epoch - 7 | Loss: 0.6887130737304688\n",
      "Epoch - 7 | Loss: 304.1650085449219\n",
      "Epoch - 7 | Loss: 17.073644638061523\n",
      "Epoch - 7 | Loss: 11.140443801879883\n",
      "Epoch - 7 | Loss: 172.9991912841797\n",
      "Epoch - 7 | Loss: 31.66290283203125\n",
      "Epoch - 7 | Loss: 131.67752075195312\n",
      "Epoch - 7 | Loss: 401.1910705566406\n",
      "Epoch - 7 | Loss: 7.597978115081787\n",
      "Epoch - 7 | Loss: 0.004296032711863518\n",
      "Epoch - 7 | Loss: 37.7801628112793\n",
      "Epoch - 7 | Loss: 25.94831085205078\n",
      "Epoch - 7 | Loss: 2.053102493286133\n",
      "Epoch - 7 | Loss: 17.420076370239258\n",
      "Epoch - 7 | Loss: 5.713592529296875\n",
      "Epoch - 7 | Loss: 195.94061279296875\n",
      "Epoch - 7 | Loss: 51.078399658203125\n",
      "Epoch - 7 | Loss: 50.13982391357422\n",
      "Epoch - 7 | Loss: 3.7483503818511963\n",
      "Epoch - 7 | Loss: 100.50662231445312\n",
      "Epoch - 7 | Loss: 24.57968521118164\n",
      "Epoch - 7 | Loss: 2.787339687347412\n",
      "Epoch - 7 | Loss: 27.182024002075195\n",
      "Epoch - 7 | Loss: 90.76482391357422\n",
      "Epoch - 7 | Loss: 10.097753524780273\n",
      "Epoch - 7 | Loss: 27.678218841552734\n",
      "Epoch - 7 | Loss: 37.6043701171875\n",
      "Epoch - 7 | Loss: 1.5030148029327393\n",
      "Epoch - 7 | Loss: 37.15861892700195\n",
      "Epoch - 7 | Loss: 6.766321182250977\n",
      "Epoch - 7 | Loss: 1.1548640727996826\n",
      "Epoch - 7 | Loss: 45.33279800415039\n",
      "Epoch - 7 | Loss: 17.521100997924805\n",
      "Epoch - 7 | Loss: 6.291993618011475\n",
      "Epoch - 7 | Loss: 3.7368671894073486\n",
      "Epoch - 7 | Loss: 9.654932975769043\n",
      "Epoch - 7 | Loss: 7.371577739715576\n",
      "Epoch - 7 | Loss: 2.833897113800049\n",
      "Epoch - 7 | Loss: 3.3837618827819824\n",
      "Epoch - 7 | Loss: 43.11869430541992\n",
      "Epoch - 7 | Loss: 29.05645179748535\n",
      "Epoch - 7 | Loss: 5.7195024490356445\n",
      "Epoch - 7 | Loss: 0.6552311778068542\n",
      "Epoch - 7 | Loss: 128.141357421875\n",
      "Epoch - 7 | Loss: 25.221895217895508\n",
      "Epoch - 7 | Loss: 0.19523032009601593\n",
      "Epoch - 7 | Loss: 1.1790282726287842\n",
      "Epoch - 7 | Loss: 58.97724914550781\n",
      "Epoch - 7 | Loss: 7.912859916687012\n",
      "Epoch - 7 | Loss: 9.473397254943848\n",
      "Epoch - 7 | Loss: 86.23424530029297\n",
      "Epoch - 7 | Loss: 1.2440710067749023\n",
      "Epoch - 7 | Loss: 10.416762351989746\n",
      "Epoch - 7 | Loss: 2.2915258407592773\n",
      "Epoch - 7 | Loss: 0.06850868463516235\n",
      "Epoch - 7 | Loss: 3.7987844944000244\n",
      "Epoch - 7 | Loss: 75.74398803710938\n",
      "Epoch - 7 | Loss: 222.68695068359375\n",
      "Epoch - 7 | Loss: 6.799962043762207\n",
      "Epoch - 7 | Loss: 89.06035614013672\n",
      "Epoch - 7 | Loss: 97.44444274902344\n",
      "Epoch - 7 | Loss: 1.4246711730957031\n",
      "Epoch - 7 | Loss: 40.39993667602539\n",
      "Epoch - 7 | Loss: 2.312570571899414\n",
      "Epoch - 7 | Loss: 0.30143845081329346\n",
      "Epoch - 7 | Loss: 2.6700894832611084\n",
      "Epoch - 7 | Loss: 8.377119064331055\n",
      "Epoch - 7 | Loss: 6.89190673828125\n",
      "Epoch - 7 | Loss: 37.27791213989258\n",
      "Epoch - 7 | Loss: 3.422720193862915\n",
      "Epoch - 7 | Loss: 23.684612274169922\n",
      "Epoch - 7 | Loss: 2.369323968887329\n",
      "Epoch - 7 | Loss: 27.499650955200195\n",
      "Epoch - 7 | Loss: 2.5327000617980957\n",
      "Epoch - 7 | Loss: 56.110355377197266\n",
      "Epoch - 7 | Loss: 26.269535064697266\n",
      "Epoch - 7 | Loss: 225.31871032714844\n",
      "Epoch - 7 | Loss: 0.621524453163147\n",
      "Epoch - 7 | Loss: 68.63218688964844\n",
      "Epoch - 7 | Loss: 21.73192024230957\n",
      "Epoch - 7 | Loss: 24.825288772583008\n",
      "Epoch - 7 | Loss: 10.654990196228027\n",
      "Epoch - 7 | Loss: 1.6130077838897705\n",
      "Epoch - 8 | Loss: 9.580968856811523\n",
      "Epoch - 8 | Loss: 41.04082107543945\n",
      "Epoch - 8 | Loss: 16.90349006652832\n",
      "Epoch - 8 | Loss: 0.956455409526825\n",
      "Epoch - 8 | Loss: 8.680259704589844\n",
      "Epoch - 8 | Loss: 58.74744415283203\n",
      "Epoch - 8 | Loss: 12.49069595336914\n",
      "Epoch - 8 | Loss: 16.05999183654785\n",
      "Epoch - 8 | Loss: 7.074523448944092\n",
      "Epoch - 8 | Loss: 0.44114112854003906\n",
      "Epoch - 8 | Loss: 279.2732849121094\n",
      "Epoch - 8 | Loss: 17.16436767578125\n",
      "Epoch - 8 | Loss: 68.65412139892578\n",
      "Epoch - 8 | Loss: 3.8846030235290527\n",
      "Epoch - 8 | Loss: 4.7458672523498535\n",
      "Epoch - 8 | Loss: 0.003381567308679223\n",
      "Epoch - 8 | Loss: 39.937862396240234\n",
      "Epoch - 8 | Loss: 5.282541275024414\n",
      "Epoch - 8 | Loss: 2.0587143898010254\n",
      "Epoch - 8 | Loss: 1.8443758487701416\n",
      "Epoch - 8 | Loss: 0.5425611734390259\n",
      "Epoch - 8 | Loss: 20.788637161254883\n",
      "Epoch - 8 | Loss: 17.789676666259766\n",
      "Epoch - 8 | Loss: 0.004906367976218462\n",
      "Epoch - 8 | Loss: 9.156197547912598\n",
      "Epoch - 8 | Loss: 51.90644454956055\n",
      "Epoch - 8 | Loss: 16.71031951904297\n",
      "Epoch - 8 | Loss: 37.85795211791992\n",
      "Epoch - 8 | Loss: 51.201541900634766\n",
      "Epoch - 8 | Loss: 22.492286682128906\n",
      "Epoch - 8 | Loss: 131.7992401123047\n",
      "Epoch - 8 | Loss: 27.93440818786621\n",
      "Epoch - 8 | Loss: 27.340007781982422\n",
      "Epoch - 8 | Loss: 106.25137329101562\n",
      "Epoch - 8 | Loss: 2.489082098007202\n",
      "Epoch - 8 | Loss: 0.8107788562774658\n",
      "Epoch - 8 | Loss: 34.87392044067383\n",
      "Epoch - 8 | Loss: 0.0222972109913826\n",
      "Epoch - 8 | Loss: 167.21923828125\n",
      "Epoch - 8 | Loss: 35.59565353393555\n",
      "Epoch - 8 | Loss: 0.31281164288520813\n",
      "Epoch - 8 | Loss: 270.4086608886719\n",
      "Epoch - 8 | Loss: 45.297359466552734\n",
      "Epoch - 8 | Loss: 28.936161041259766\n",
      "Epoch - 8 | Loss: 4.43659782409668\n",
      "Epoch - 8 | Loss: 105.13727569580078\n",
      "Epoch - 8 | Loss: 3.4184305667877197\n",
      "Epoch - 8 | Loss: 0.7293487191200256\n",
      "Epoch - 8 | Loss: 304.7291564941406\n",
      "Epoch - 8 | Loss: 17.188966751098633\n",
      "Epoch - 8 | Loss: 11.094502449035645\n",
      "Epoch - 8 | Loss: 172.95103454589844\n",
      "Epoch - 8 | Loss: 31.658008575439453\n",
      "Epoch - 8 | Loss: 131.5840301513672\n",
      "Epoch - 8 | Loss: 400.89617919921875\n",
      "Epoch - 8 | Loss: 7.662339687347412\n",
      "Epoch - 8 | Loss: 0.007180814165621996\n",
      "Epoch - 8 | Loss: 37.498897552490234\n",
      "Epoch - 8 | Loss: 26.292768478393555\n",
      "Epoch - 8 | Loss: 2.1327335834503174\n",
      "Epoch - 8 | Loss: 17.757770538330078\n",
      "Epoch - 8 | Loss: 5.912542343139648\n",
      "Epoch - 8 | Loss: 197.0689239501953\n",
      "Epoch - 8 | Loss: 50.564910888671875\n",
      "Epoch - 8 | Loss: 49.6495246887207\n",
      "Epoch - 8 | Loss: 3.92219614982605\n",
      "Epoch - 8 | Loss: 101.23763275146484\n",
      "Epoch - 8 | Loss: 24.95195770263672\n",
      "Epoch - 8 | Loss: 2.9315378665924072\n",
      "Epoch - 8 | Loss: 27.636089324951172\n",
      "Epoch - 8 | Loss: 90.10871887207031\n",
      "Epoch - 8 | Loss: 9.857823371887207\n",
      "Epoch - 8 | Loss: 28.100223541259766\n",
      "Epoch - 8 | Loss: 38.07603454589844\n",
      "Epoch - 8 | Loss: 1.415688157081604\n",
      "Epoch - 8 | Loss: 36.74382400512695\n",
      "Epoch - 8 | Loss: 6.623518943786621\n",
      "Epoch - 8 | Loss: 1.2269916534423828\n",
      "Epoch - 8 | Loss: 45.775333404541016\n",
      "Epoch - 8 | Loss: 17.258689880371094\n",
      "Epoch - 8 | Loss: 6.437969207763672\n",
      "Epoch - 8 | Loss: 3.8298070430755615\n",
      "Epoch - 8 | Loss: 9.826468467712402\n",
      "Epoch - 8 | Loss: 7.257452487945557\n",
      "Epoch - 8 | Loss: 2.917785882949829\n",
      "Epoch - 8 | Loss: 3.299276351928711\n",
      "Epoch - 8 | Loss: 43.39417266845703\n",
      "Epoch - 8 | Loss: 29.25815200805664\n",
      "Epoch - 8 | Loss: 5.6391754150390625\n",
      "Epoch - 8 | Loss: 0.6284970045089722\n",
      "Epoch - 8 | Loss: 127.8516845703125\n",
      "Epoch - 8 | Loss: 25.36248016357422\n",
      "Epoch - 8 | Loss: 0.2062983214855194\n",
      "Epoch - 8 | Loss: 1.2065247297286987\n",
      "Epoch - 8 | Loss: 59.162776947021484\n",
      "Epoch - 8 | Loss: 7.960834503173828\n",
      "Epoch - 8 | Loss: 9.519478797912598\n",
      "Epoch - 8 | Loss: 86.30085754394531\n",
      "Epoch - 8 | Loss: 1.242607831954956\n",
      "Epoch - 8 | Loss: 10.401402473449707\n",
      "Epoch - 8 | Loss: 2.3078625202178955\n",
      "Epoch - 8 | Loss: 0.06423226743936539\n",
      "Epoch - 8 | Loss: 3.835422992706299\n",
      "Epoch - 8 | Loss: 75.52144622802734\n",
      "Epoch - 8 | Loss: 222.2869415283203\n",
      "Epoch - 8 | Loss: 6.908059597015381\n",
      "Epoch - 8 | Loss: 89.52940368652344\n",
      "Epoch - 8 | Loss: 97.89359283447266\n",
      "Epoch - 8 | Loss: 1.489855408668518\n",
      "Epoch - 8 | Loss: 40.0594596862793\n",
      "Epoch - 8 | Loss: 2.3950650691986084\n",
      "Epoch - 8 | Loss: 0.3341403007507324\n",
      "Epoch - 8 | Loss: 2.575815439224243\n",
      "Epoch - 8 | Loss: 8.558231353759766\n",
      "Epoch - 8 | Loss: 6.737951755523682\n",
      "Epoch - 8 | Loss: 37.613868713378906\n",
      "Epoch - 8 | Loss: 3.312093496322632\n",
      "Epoch - 8 | Loss: 23.930341720581055\n",
      "Epoch - 8 | Loss: 2.2841172218322754\n",
      "Epoch - 8 | Loss: 27.24968719482422\n",
      "Epoch - 8 | Loss: 2.461259126663208\n",
      "Epoch - 8 | Loss: 55.734256744384766\n",
      "Epoch - 8 | Loss: 26.55930519104004\n",
      "Epoch - 8 | Loss: 226.05821228027344\n",
      "Epoch - 8 | Loss: 0.5805060863494873\n",
      "Epoch - 8 | Loss: 69.05859375\n",
      "Epoch - 8 | Loss: 21.525842666625977\n",
      "Epoch - 8 | Loss: 25.037092208862305\n",
      "Epoch - 8 | Loss: 10.531131744384766\n",
      "Epoch - 8 | Loss: 1.6486766338348389\n",
      "Epoch - 9 | Loss: 9.673859596252441\n",
      "Epoch - 9 | Loss: 40.887786865234375\n",
      "Epoch - 9 | Loss: 16.81818389892578\n",
      "Epoch - 9 | Loss: 0.9378927946090698\n",
      "Epoch - 9 | Loss: 8.61613655090332\n",
      "Epoch - 9 | Loss: 58.59526824951172\n",
      "Epoch - 9 | Loss: 12.577940940856934\n",
      "Epoch - 9 | Loss: 15.950660705566406\n",
      "Epoch - 9 | Loss: 7.004283428192139\n",
      "Epoch - 9 | Loss: 0.42025354504585266\n",
      "Epoch - 9 | Loss: 279.8991394042969\n",
      "Epoch - 9 | Loss: 17.033567428588867\n",
      "Epoch - 9 | Loss: 68.86421966552734\n",
      "Epoch - 9 | Loss: 3.926820993423462\n",
      "Epoch - 9 | Loss: 4.784038066864014\n",
      "Epoch - 9 | Loss: 0.0025125278625637293\n",
      "Epoch - 9 | Loss: 39.860469818115234\n",
      "Epoch - 9 | Loss: 5.259420394897461\n",
      "Epoch - 9 | Loss: 2.0446391105651855\n",
      "Epoch - 9 | Loss: 1.8316328525543213\n",
      "Epoch - 9 | Loss: 0.5353359580039978\n",
      "Epoch - 9 | Loss: 20.74073028564453\n",
      "Epoch - 9 | Loss: 17.74169921875\n",
      "Epoch - 9 | Loss: 0.0038871997967362404\n",
      "Epoch - 9 | Loss: 9.203954696655273\n",
      "Epoch - 9 | Loss: 51.774169921875\n",
      "Epoch - 9 | Loss: 16.79450798034668\n",
      "Epoch - 9 | Loss: 37.99030685424805\n",
      "Epoch - 9 | Loss: 51.026451110839844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 9 | Loss: 22.381990432739258\n",
      "Epoch - 9 | Loss: 131.515869140625\n",
      "Epoch - 9 | Loss: 27.742155075073242\n",
      "Epoch - 9 | Loss: 27.156333923339844\n",
      "Epoch - 9 | Loss: 105.83709716796875\n",
      "Epoch - 9 | Loss: 2.5868964195251465\n",
      "Epoch - 9 | Loss: 0.7596352696418762\n",
      "Epoch - 9 | Loss: 35.226051330566406\n",
      "Epoch - 9 | Loss: 0.01324908621609211\n",
      "Epoch - 9 | Loss: 168.44285583496094\n",
      "Epoch - 9 | Loss: 36.0395622253418\n",
      "Epoch - 9 | Loss: 0.3584800064563751\n",
      "Epoch - 9 | Loss: 271.85662841796875\n",
      "Epoch - 9 | Loss: 45.674991607666016\n",
      "Epoch - 9 | Loss: 28.631954193115234\n",
      "Epoch - 9 | Loss: 4.335012912750244\n",
      "Epoch - 9 | Loss: 105.54853820800781\n",
      "Epoch - 9 | Loss: 3.4742767810821533\n",
      "Epoch - 9 | Loss: 0.7541062831878662\n",
      "Epoch - 9 | Loss: 305.0323486328125\n",
      "Epoch - 9 | Loss: 17.22403335571289\n",
      "Epoch - 9 | Loss: 11.10782241821289\n",
      "Epoch - 9 | Loss: 173.09634399414062\n",
      "Epoch - 9 | Loss: 31.57246971130371\n",
      "Epoch - 9 | Loss: 131.3034210205078\n",
      "Epoch - 9 | Loss: 400.32568359375\n",
      "Epoch - 9 | Loss: 7.759305477142334\n",
      "Epoch - 9 | Loss: 0.012197681702673435\n",
      "Epoch - 9 | Loss: 37.14513397216797\n",
      "Epoch - 9 | Loss: 26.71176528930664\n",
      "Epoch - 9 | Loss: 2.2286391258239746\n",
      "Epoch - 9 | Loss: 18.152494430541992\n",
      "Epoch - 9 | Loss: 6.144174098968506\n",
      "Epoch - 9 | Loss: 198.3515167236328\n",
      "Epoch - 9 | Loss: 49.98678207397461\n",
      "Epoch - 9 | Loss: 49.099971771240234\n",
      "Epoch - 9 | Loss: 4.121328830718994\n",
      "Epoch - 9 | Loss: 102.05420684814453\n",
      "Epoch - 9 | Loss: 25.368820190429688\n",
      "Epoch - 9 | Loss: 3.0959694385528564\n",
      "Epoch - 9 | Loss: 28.145051956176758\n",
      "Epoch - 9 | Loss: 89.38032531738281\n",
      "Epoch - 9 | Loss: 9.594292640686035\n",
      "Epoch - 9 | Loss: 28.57181167602539\n",
      "Epoch - 9 | Loss: 38.6022834777832\n",
      "Epoch - 9 | Loss: 1.3217666149139404\n",
      "Epoch - 9 | Loss: 36.28538513183594\n",
      "Epoch - 9 | Loss: 6.4669036865234375\n",
      "Epoch - 9 | Loss: 1.3091659545898438\n",
      "Epoch - 9 | Loss: 46.264739990234375\n",
      "Epoch - 9 | Loss: 16.97197151184082\n",
      "Epoch - 9 | Loss: 6.600193500518799\n",
      "Epoch - 9 | Loss: 3.9330523014068604\n",
      "Epoch - 9 | Loss: 10.016216278076172\n",
      "Epoch - 9 | Loss: 7.133127689361572\n",
      "Epoch - 9 | Loss: 3.011233329772949\n",
      "Epoch - 9 | Loss: 3.207709550857544\n",
      "Epoch - 9 | Loss: 43.69725036621094\n",
      "Epoch - 9 | Loss: 29.481008529663086\n",
      "Epoch - 9 | Loss: 5.5506415367126465\n",
      "Epoch - 9 | Loss: 0.5992563962936401\n",
      "Epoch - 9 | Loss: 127.52562713623047\n",
      "Epoch - 9 | Loss: 25.519718170166016\n",
      "Epoch - 9 | Loss: 0.21898332238197327\n",
      "Epoch - 9 | Loss: 1.2374763488769531\n",
      "Epoch - 9 | Loss: 59.36952209472656\n",
      "Epoch - 9 | Loss: 8.015259742736816\n",
      "Epoch - 9 | Loss: 9.573177337646484\n",
      "Epoch - 9 | Loss: 86.38507843017578\n",
      "Epoch - 9 | Loss: 1.2387837171554565\n",
      "Epoch - 9 | Loss: 10.39318561553955\n",
      "Epoch - 9 | Loss: 2.321326732635498\n",
      "Epoch - 9 | Loss: 0.06060344725847244\n",
      "Epoch - 9 | Loss: 3.8690102100372314\n",
      "Epoch - 9 | Loss: 75.31684875488281\n",
      "Epoch - 9 | Loss: 221.91172790527344\n",
      "Epoch - 9 | Loss: 7.011029243469238\n",
      "Epoch - 9 | Loss: 89.97695922851562\n",
      "Epoch - 9 | Loss: 98.32388305664062\n",
      "Epoch - 9 | Loss: 1.5534532070159912\n",
      "Epoch - 9 | Loss: 39.73551940917969\n",
      "Epoch - 9 | Loss: 2.475306987762451\n",
      "Epoch - 9 | Loss: 0.3669528067111969\n",
      "Epoch - 9 | Loss: 2.4873249530792236\n",
      "Epoch - 9 | Loss: 8.732937812805176\n",
      "Epoch - 9 | Loss: 6.592590808868408\n",
      "Epoch - 9 | Loss: 37.936012268066406\n",
      "Epoch - 9 | Loss: 3.208529472351074\n",
      "Epoch - 9 | Loss: 24.165409088134766\n",
      "Epoch - 9 | Loss: 2.2048869132995605\n",
      "Epoch - 9 | Loss: 27.014108657836914\n",
      "Epoch - 9 | Loss: 2.3946046829223633\n",
      "Epoch - 9 | Loss: 55.38065719604492\n",
      "Epoch - 9 | Loss: 26.833904266357422\n",
      "Epoch - 9 | Loss: 226.7567596435547\n",
      "Epoch - 9 | Loss: 0.5433707237243652\n",
      "Epoch - 9 | Loss: 69.45707702636719\n",
      "Epoch - 9 | Loss: 21.336177825927734\n",
      "Epoch - 9 | Loss: 25.231935501098633\n",
      "Epoch - 9 | Loss: 10.419716835021973\n",
      "Epoch - 9 | Loss: 1.6811922788619995\n",
      "Epoch - 10 | Loss: 9.75613784790039\n",
      "Epoch - 10 | Loss: 40.75519943237305\n",
      "Epoch - 10 | Loss: 16.7451114654541\n",
      "Epoch - 10 | Loss: 0.9221256375312805\n",
      "Epoch - 10 | Loss: 8.562383651733398\n",
      "Epoch - 10 | Loss: 58.46592330932617\n",
      "Epoch - 10 | Loss: 12.652731895446777\n",
      "Epoch - 10 | Loss: 15.85749626159668\n",
      "Epoch - 10 | Loss: 6.943517684936523\n",
      "Epoch - 10 | Loss: 0.4024238884449005\n",
      "Epoch - 10 | Loss: 280.44879150390625\n",
      "Epoch - 10 | Loss: 16.9205265045166\n",
      "Epoch - 10 | Loss: 69.04635620117188\n",
      "Epoch - 10 | Loss: 3.9627792835235596\n",
      "Epoch - 10 | Loss: 4.815545558929443\n",
      "Epoch - 10 | Loss: 0.0019392454996705055\n",
      "Epoch - 10 | Loss: 39.8079833984375\n",
      "Epoch - 10 | Loss: 5.244174003601074\n",
      "Epoch - 10 | Loss: 2.036007881164551\n",
      "Epoch - 10 | Loss: 1.8237526416778564\n",
      "Epoch - 10 | Loss: 0.5309017896652222\n",
      "Epoch - 10 | Loss: 20.711069107055664\n",
      "Epoch - 10 | Loss: 17.707971572875977\n",
      "Epoch - 10 | Loss: 0.003210753668099642\n",
      "Epoch - 10 | Loss: 9.241837501525879\n",
      "Epoch - 10 | Loss: 51.66893005371094\n",
      "Epoch - 10 | Loss: 16.864553451538086\n",
      "Epoch - 10 | Loss: 38.10211944580078\n",
      "Epoch - 10 | Loss: 50.880714416503906\n",
      "Epoch - 10 | Loss: 22.2878475189209\n",
      "Epoch - 10 | Loss: 131.2692413330078\n",
      "Epoch - 10 | Loss: 27.573556900024414\n",
      "Epoch - 10 | Loss: 26.991191864013672\n",
      "Epoch - 10 | Loss: 105.45919799804688\n",
      "Epoch - 10 | Loss: 2.678473711013794\n",
      "Epoch - 10 | Loss: 0.7136532068252563\n",
      "Epoch - 10 | Loss: 35.55638122558594\n",
      "Epoch - 10 | Loss: 0.00690804049372673\n",
      "Epoch - 10 | Loss: 169.58946228027344\n",
      "Epoch - 10 | Loss: 36.45691680908203\n",
      "Epoch - 10 | Loss: 0.4037801921367645\n",
      "Epoch - 10 | Loss: 273.2010192871094\n",
      "Epoch - 10 | Loss: 46.024784088134766\n",
      "Epoch - 10 | Loss: 28.3570556640625\n",
      "Epoch - 10 | Loss: 4.245004653930664\n",
      "Epoch - 10 | Loss: 105.9126968383789\n",
      "Epoch - 10 | Loss: 3.522881507873535\n",
      "Epoch - 10 | Loss: 0.7745562791824341\n",
      "Epoch - 10 | Loss: 305.2650451660156\n",
      "Epoch - 10 | Loss: 17.237333297729492\n",
      "Epoch - 10 | Loss: 11.136930465698242\n",
      "Epoch - 10 | Loss: 173.29173278808594\n",
      "Epoch - 10 | Loss: 31.466415405273438\n",
      "Epoch - 10 | Loss: 130.9752655029297\n",
      "Epoch - 10 | Loss: 399.6878662109375\n",
      "Epoch - 10 | Loss: 7.864388942718506\n",
      "Epoch - 10 | Loss: 0.01893269456923008\n",
      "Epoch - 10 | Loss: 36.77777862548828\n",
      "Epoch - 10 | Loss: 27.148462295532227\n",
      "Epoch - 10 | Loss: 2.329296112060547\n",
      "Epoch - 10 | Loss: 18.560758590698242\n",
      "Epoch - 10 | Loss: 6.384921550750732\n",
      "Epoch - 10 | Loss: 199.65940856933594\n",
      "Epoch - 10 | Loss: 49.40377426147461\n",
      "Epoch - 10 | Loss: 48.546783447265625\n",
      "Epoch - 10 | Loss: 4.327550411224365\n",
      "Epoch - 10 | Loss: 102.88009643554688\n",
      "Epoch - 10 | Loss: 25.791614532470703\n",
      "Epoch - 10 | Loss: 3.265852689743042\n",
      "Epoch - 10 | Loss: 28.660863876342773\n",
      "Epoch - 10 | Loss: 88.65330505371094\n",
      "Epoch - 10 | Loss: 9.334192276000977\n",
      "Epoch - 10 | Loss: 29.04658317565918\n",
      "Epoch - 10 | Loss: 39.129764556884766\n",
      "Epoch - 10 | Loss: 1.2316440343856812\n",
      "Epoch - 10 | Loss: 35.83393096923828\n",
      "Epoch - 10 | Loss: 6.314231872558594\n",
      "Epoch - 10 | Loss: 1.3926888704299927\n",
      "Epoch - 10 | Loss: 46.74756622314453\n",
      "Epoch - 10 | Loss: 16.69388771057129\n",
      "Epoch - 10 | Loss: 6.760071277618408\n",
      "Epoch - 10 | Loss: 4.034344673156738\n",
      "Epoch - 10 | Loss: 10.201345443725586\n",
      "Epoch - 10 | Loss: 7.014928340911865\n",
      "Epoch - 10 | Loss: 3.102013349533081\n",
      "Epoch - 10 | Loss: 3.1217706203460693\n",
      "Epoch - 10 | Loss: 43.98479080200195\n",
      "Epoch - 10 | Loss: 29.690824508666992\n",
      "Epoch - 10 | Loss: 5.469015121459961\n",
      "Epoch - 10 | Loss: 0.5729623436927795\n",
      "Epoch - 10 | Loss: 127.23079681396484\n",
      "Epoch - 10 | Loss: 25.66197967529297\n",
      "Epoch - 10 | Loss: 0.2306230068206787\n",
      "Epoch - 10 | Loss: 1.2651615142822266\n",
      "Epoch - 10 | Loss: 59.55025100708008\n",
      "Epoch - 10 | Loss: 8.061116218566895\n",
      "Epoch - 10 | Loss: 9.61656665802002\n",
      "Epoch - 10 | Loss: 86.4425277709961\n",
      "Epoch - 10 | Loss: 1.2384101152420044\n",
      "Epoch - 10 | Loss: 10.375041961669922\n",
      "Epoch - 10 | Loss: 2.33902907371521\n",
      "Epoch - 10 | Loss: 0.056404076516628265\n",
      "Epoch - 10 | Loss: 3.907432794570923\n",
      "Epoch - 10 | Loss: 75.08924865722656\n",
      "Epoch - 10 | Loss: 221.5044708251953\n",
      "Epoch - 10 | Loss: 7.12106990814209\n",
      "Epoch - 10 | Loss: 90.44623565673828\n",
      "Epoch - 10 | Loss: 98.77308654785156\n",
      "Epoch - 10 | Loss: 1.6208853721618652\n",
      "Epoch - 10 | Loss: 39.401119232177734\n",
      "Epoch - 10 | Loss: 2.5596044063568115\n",
      "Epoch - 10 | Loss: 0.4023561477661133\n",
      "Epoch - 10 | Loss: 2.3980886936187744\n",
      "Epoch - 10 | Loss: 8.913554191589355\n",
      "Epoch - 10 | Loss: 6.445792198181152\n",
      "Epoch - 10 | Loss: 38.265663146972656\n",
      "Epoch - 10 | Loss: 3.104997158050537\n",
      "Epoch - 10 | Loss: 24.405282974243164\n",
      "Epoch - 10 | Loss: 2.126053810119629\n",
      "Epoch - 10 | Loss: 26.77678680419922\n",
      "Epoch - 10 | Loss: 2.3282947540283203\n",
      "Epoch - 10 | Loss: 55.02671432495117\n",
      "Epoch - 10 | Loss: 27.10983657836914\n",
      "Epoch - 10 | Loss: 227.4550018310547\n",
      "Epoch - 10 | Loss: 0.5076366662979126\n",
      "Epoch - 10 | Loss: 69.85338592529297\n",
      "Epoch - 10 | Loss: 21.149038314819336\n",
      "Epoch - 10 | Loss: 25.42506980895996\n",
      "Epoch - 10 | Loss: 10.31075668334961\n",
      "Epoch - 10 | Loss: 1.7134760618209839\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(10):\n",
    "    for data_,label in zip(x_tensor,y_tensor):\n",
    "        optimize.zero_grad()\n",
    "        bashorat = model(data_)\n",
    "        xato = criterion(bashorat,label)\n",
    "        xato.backward()\n",
    "        optimize.step()\n",
    "\n",
    "        print(f\"Epoch - {epoch+1} | Loss: {xato.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "148e2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.Tensor(x_test)\n",
    "y_test = torch.Tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a67afd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :   6.0606060606060606%\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    Xato=0;Togri=0\n",
    "    for data_,label in zip(x_test,y_test):\n",
    "        \n",
    "        bashorat = model(data_)\n",
    "        Xato += criterion(bashorat,label).item()\n",
    "        if int(bashorat.detach().numpy()[0]) == int(label):\n",
    "            Togri += 1\n",
    "        \n",
    "    print(f\"accuracy :   {100.0*Togri/len(x_test)}%\")\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
